# 从零到一：用 AI IDE 快速实现你的产品想法

> 以 Ummm 语音输入工具为例，教你如何用 AI IDE 在几小时内从想法变成可发布的产品

## 目录

1. [项目背景](#项目背景)
2. [准备工作](#准备工作)
3. [第一阶段：验证想法](#第一阶段验证想法)
4. [第二阶段：核心功能开发](#第二阶段核心功能开发)
5. [第三阶段：UI 设计与交互](#第三阶段ui-设计与交互)
6. [第四阶段：打包与分发](#第四阶段打包与分发)
7. [第五阶段：Landing 页面](#第五阶段landing-页面)
8. [进阶：接入云端 ASR](#进阶接入云端-asr)
9. [总结与心得](#总结与心得)

---

## 项目背景

**痛点**：打字太慢，效率低下。语音输入比打字快 3 倍，但现有工具要么不好用，要么隐私堪忧。

**想法**：做一个按住即说、松开即输的语音输入工具，像 Typeless 一样简洁优雅。

**最终成果**：
- 完整的 macOS 菜单栏应用
- 支持系统本地识别 + 阿里云 ASR
- 精美的 Landing 页面
- 可分发的 DMG 安装包

---

## 准备工作

### 1. 安装 AI IDE
推荐使用支持 AI 编程的 IDE（如 Cursor、Qodo 等）

### 2. 基础环境
- macOS 12.0+
- Xcode Command Line Tools：`xcode-select --install`

### 3. 心态准备
- 不需要精通 Swift，AI 会帮你写代码
- 专注于描述需求，让 AI 实现细节
- 遇到问题直接问，不要怕"不懂"

---

## 第一阶段：验证想法

### 快速原型验证

**Prompt 示例**：
```
帮我写一个 Swift 脚本，测试 macOS 的语音识别 API：
1. 用系统的 Speech 框架
2. 录音 5 秒，输出识别结果
3. 先不做 UI，命令行能跑就行
```

AI 会生成一个测试脚本（类似项目中的 `test_asr.swift`），你可以直接运行验证：

```bash
swift test_asr.swift
```

**验证要点**：
- 语音识别是否可用？
- 延迟如何？
- 中文识别准确率？

> 💡 **技巧**：先用最小代码验证核心功能是否可行，再考虑完整产品

---

## 第二阶段：核心功能开发

### 2.1 创建项目结构

**Prompt 示例**：
```
帮我创建一个 macOS 菜单栏应用的基础结构：
- 使用 SwiftUI
- 应用启动后在菜单栏显示图标
- 隐藏 Dock 图标
- 点击菜单栏图标显示一个简单的弹窗
```

### 2.2 实现语音识别核心

**Prompt 示例**：
```
帮我实现一个 SpeechRecognizer 类：
1. 封装 macOS 的 Speech 框架
2. 支持实时流式识别（边说边出文字）
3. 自动处理权限请求
4. 计算音量级别用于显示波形
5. 支持静音自动停止
```

AI 会生成完整的 `SpeechRecognizer.swift`，包含：
- 权限管理
- 音频引擎配置
- 实时识别回调
- 错误处理

### 2.3 实现全局快捷键

**Prompt 示例**：
```
帮我实现全局快捷键监听：
1. 默认用 fn 键作为触发键
2. 按住开始录音，松开停止
3. 支持自定义修改快捷键
4. 需要处理辅助功能权限
```

生成的 `HotkeyManager.swift` 会使用 Carbon 框架处理底层事件。

### 2.4 实现文字输入

**Prompt 示例**：
```
识别完成后，如何把文字自动输入到当前光标位置？
不要用 AppleScript，要用模拟键盘的方式
```

AI 会实现通过 `CGEvent` 模拟 Cmd+V 粘贴的方案。

---

## 第三阶段：UI 设计与交互

### 3.1 浮动指示器

**Prompt 示例**：
```
帮我设计一个录音时的浮动指示器窗口：
- 类似 Typeless 的风格，极简深色
- 显示波形动画，根据音量变化
- 实时显示识别文字
- 有复制和插入按钮
- 圆角毛玻璃效果
```

### 3.2 菜单栏弹窗

**Prompt 示例**：
```
帮我设计菜单栏弹窗：
- 可以设置 API Key
- 可以修改快捷键
- 显示当前使用的识别引擎
- 苹果风格的简洁设计
```

> 💡 **技巧**：给 AI 参考图片或描述你喜欢的 App 风格，效果更好

---

## 第四阶段：打包与分发

### 4.1 编译脚本

**Prompt 示例**：
```
帮我写一个 Shell 脚本编译这个 Swift 项目：
1. 不用 Xcode，用 swiftc 命令行
2. 编译成 Universal Binary（支持 Intel 和 Apple Silicon）
3. 创建标准的 .app 包结构
4. 自动代码签名
```

生成的 `build.sh` 可以一键编译：

```bash
./build.sh
```

### 4.2 创建应用图标

**Prompt 示例**：
```
帮我写一个 Swift 脚本，用代码生成应用图标：
- 画一个简约的波形图标
- 生成所有需要的尺寸
- 输出 icns 文件
```

### 4.3 打包 DMG

**Prompt 示例**：
```
帮我写一个脚本创建 DMG 安装包：
- 包含 Applications 文件夹快捷方式
- 用户可以直接拖拽安装
- 设置好窗口大小和图标位置
```

### 4.4 上传分发

安装包可以上传到：
- **阿里云 OSS**（国内快）
- **GitHub Releases**（国际化）

---

## 第五阶段：Landing 页面

### 5.1 生成页面

**Prompt 示例**：
```
帮我设计一个 Landing 页面：
- 产品名叫 Ummm，一个 macOS 语音输入工具
- 苹果官网风格，简洁大气
- 支持中英文切换
- 包含功能介绍、使用方法、下载按钮
- 有动效演示
```

### 5.2 部署上线

```bash
# 初始化 Git
cd landing
git init
git add .
git commit -m "Initial commit"

# 创建 GitHub 仓库并推送
gh repo create ummm-landing --public --source=. --push

# 部署到 Vercel
npx vercel --yes
```

---

## 进阶：接入云端 ASR

系统自带的语音识别对中文支持一般，可以接入阿里云 ASR 提升准确率。

**Prompt 示例**：
```
帮我接入阿里云实时语音识别 API：
- 使用 WebSocket 流式传输
- 参考这份 API 文档（附上 asrapi.md）
- 支持降噪和语气词过滤
- 区分最终结果和中间结果
```

**获取 API Key**：
访问 [阿里云百炼 - 语音模型体验中心](https://bailian.console.aliyun.com/cn-beijing/?source_channel=%22ummm%22/?tab=model#/efm/model_experience_center/voice)

---

## 总结与心得

### AI IDE 开发流程

```
想法 → 验证可行性 → 核心功能 → UI 交互 → 打包分发 → 推广页面
  ↓         ↓           ↓         ↓          ↓          ↓
简单描述   写测试脚本   逐步实现   描述风格    写脚本      一句话生成
```

### 与 AI 协作的技巧

1. **先说目标，再说细节**
   - ❌ "用 SwiftUI 写一个 VStack 里面放 HStack..."
   - ✅ "帮我做一个显示音量波形的动画组件"

2. **分步骤推进**
   - 不要一次性要求所有功能
   - 每完成一步，测试验证后再继续

3. **给上下文**
   - 告诉 AI 你在做什么项目
   - 分享已有的代码让 AI 理解结构

4. **遇到问题直接问**
   - "这段代码报错了：xxx"
   - "为什么识别结果有延迟？"

5. **迭代优化**
   - "这个 UI 不够好看，参考 Apple 的设计改一下"
   - "性能有问题，帮我优化"

### 项目文件结构

```
apple_asr_test/
├── Ummm/                    # 源代码
│   ├── UmmmApp.swift        # 应用入口
│   ├── ContentView.swift    # UI 视图
│   ├── SpeechRecognizer.swift # 语音识别
│   ├── HotkeyManager.swift  # 快捷键管理
│   ├── AliyunASR.swift      # 阿里云 ASR
│   └── Info.plist           # 应用配置
├── landing/                 # Landing 页面
│   ├── index.html
│   ├── style.css
│   └── script.js
├── build.sh                 # 编译脚本
├── create_dmg.sh            # 打包脚本
└── create_icon.swift        # 图标生成
```

### 时间估算

| 阶段 | 传统开发 | AI 辅助开发 |
|------|---------|------------|
| 验证想法 | 2-3 天 | 30 分钟 |
| 核心功能 | 1-2 周 | 2-3 小时 |
| UI 设计 | 3-5 天 | 1-2 小时 |
| 打包分发 | 1 天 | 30 分钟 |
| Landing 页面 | 2-3 天 | 1 小时 |
| **总计** | **3-4 周** | **1 天** |

---

## 开始你的项目

现在轮到你了！想一个你一直想做但觉得太难的想法，用 AI IDE 试试看。

记住：**不需要精通编程，只需要清楚地描述你想要什么。**

祝你创造出下一个好产品！🚀
